{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clasterización**\n",
    "\n",
    "En este archivo realizaremos una clasterización que verifica los siguientes puntos:\n",
    "- Aprendizaje No-Supervisado en Python.\n",
    "- Ingeniería de variables (Feature engineering).\n",
    "- Centroid-based Clustering (K-Means , Mean-Shift & Mini-Batch K-Means).\n",
    "- Density-based clustering (DBSCAN, OPTICS).\n",
    "- Distribution-based clustering (GMM).\n",
    "- Hierarchical clustering (Agglomerative Clustering).\n",
    "\n",
    "Primero importamos todas las librerías que usaremos y las instalamos en caso de ser necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo hacemos que el código sea de aprendizaje no supervisado?**\n",
    "\n",
    "El aprendizaje no supervisado se aplica en este código a través de los algoritmos de clustering que se utilizan para agrupar los datos en grupos o clusters sin la necesidad de tener etiquetas de clase predefinidas. \n",
    "\n",
    "Estos algoritmos son ejemplos de técnicas de aprendizaje no supervisado que se utilizan para encontrar patrones y estructuras subyacentes en los datos sin necesidad de información previa sobre las clases a las que pertenecen los datos. El objetivo es agrupar los datos en grupos similares o \"clústeres\" basándose únicamente en la similitud entre las muestras. Cada algoritmo tiene su propio enfoque para realizar esta tarea, como la minimización de la distancia intra-cluster en el caso de K-Means o la detección de densidades locales en el caso de DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# Instalamos las librerías necesarias\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MeanShift, DBSCAN, OPTICS, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El próximo paso es cargar los datos limpios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Country</th>\n",
       "      <th># Pl</th>\n",
       "      <th>Age</th>\n",
       "      <th>MP</th>\n",
       "      <th>Starts</th>\n",
       "      <th>Gls</th>\n",
       "      <th>Ast</th>\n",
       "      <th>G+A</th>\n",
       "      <th>G-PK</th>\n",
       "      <th>PK</th>\n",
       "      <th>PKatt</th>\n",
       "      <th>CrdY</th>\n",
       "      <th>CrdR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Países bajos</td>\n",
       "      <td>19</td>\n",
       "      <td>26.4</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Atlético Madrid</td>\n",
       "      <td>España</td>\n",
       "      <td>22</td>\n",
       "      <td>28.6</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>España</td>\n",
       "      <td>26</td>\n",
       "      <td>26.4</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>Alemania</td>\n",
       "      <td>24</td>\n",
       "      <td>26.6</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Benfica</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>24</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season            Squad       Country  # Pl   Age  MP  Starts  Gls  Ast  \\\n",
       "0  2022-2023             Ajax  Países bajos    19  26.4   6      66   11    9   \n",
       "1  2022-2023  Atlético Madrid        España    22  28.6   6      66    4    3   \n",
       "2  2022-2023        Barcelona        España    26  26.4   6      66   12   10   \n",
       "3  2022-2023    Bayern Munich      Alemania    24  26.6  10     110   21   19   \n",
       "4  2022-2023          Benfica      Portugal    24  26.0  10     110   25   16   \n",
       "\n",
       "   G+A  G-PK  PK  PKatt  CrdY  CrdR  \n",
       "0   20    10   1      1  15.0   1.0  \n",
       "1    7     4   0      2  11.0   0.0  \n",
       "2   22    12   0      0   9.0   0.0  \n",
       "3   40    20   1      1  20.0   1.0  \n",
       "4   41    20   5      5  19.0   0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv('../data/equipos_limpio.csv')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comenzamos con un preprocesamiento de los datos que puede considerarse como una forma básica de ingeniería de variables. En nuestro caso es el manejo de valores faltantes, eliminación de columnas irrelevantes y el escalado de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 640 entries, 0 to 639\n",
      "Data columns (total 15 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Season   640 non-null    object \n",
      " 1   Squad    640 non-null    object \n",
      " 2   Country  640 non-null    object \n",
      " 3   # Pl     640 non-null    int64  \n",
      " 4   Age      640 non-null    float64\n",
      " 5   MP       640 non-null    int64  \n",
      " 6   Starts   640 non-null    int64  \n",
      " 7   Gls      640 non-null    int64  \n",
      " 8   Ast      640 non-null    int64  \n",
      " 9   G+A      640 non-null    int64  \n",
      " 10  G-PK     640 non-null    int64  \n",
      " 11  PK       640 non-null    int64  \n",
      " 12  PKatt    640 non-null    int64  \n",
      " 13  CrdY     576 non-null    float64\n",
      " 14  CrdR     576 non-null    float64\n",
      "dtypes: float64(3), int64(9), object(3)\n",
      "memory usage: 75.1+ KB\n"
     ]
    }
   ],
   "source": [
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que todavía tenemos algunas filas nulas. Al limpiar los datos no nos importaba tener algunas filas nulas, pero para hacer la clasterización es muy importante no contar con ningún dato de este tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 576 entries, 0 to 639\n",
      "Data columns (total 15 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Season   576 non-null    object \n",
      " 1   Squad    576 non-null    object \n",
      " 2   Country  576 non-null    object \n",
      " 3   # Pl     576 non-null    int64  \n",
      " 4   Age      576 non-null    float64\n",
      " 5   MP       576 non-null    int64  \n",
      " 6   Starts   576 non-null    int64  \n",
      " 7   Gls      576 non-null    int64  \n",
      " 8   Ast      576 non-null    int64  \n",
      " 9   G+A      576 non-null    int64  \n",
      " 10  G-PK     576 non-null    int64  \n",
      " 11  PK       576 non-null    int64  \n",
      " 12  PKatt    576 non-null    int64  \n",
      " 13  CrdY     576 non-null    float64\n",
      " 14  CrdR     576 non-null    float64\n",
      "dtypes: float64(3), int64(9), object(3)\n",
      "memory usage: 72.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos las filas que contienen valores nulos\n",
    "datos = datos.dropna()\n",
    "\n",
    "# Vemos que se ha hecho el cambio correctamente\n",
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que hay algunas variables categóricas que podríamos pasar a numéricas, pues nos podrían ayudar en nuestra predicción posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-2023' '2021-2022' '2020-2021' '2019-2020' '2018-2019' '2016-2017'\n",
      " '2014-2015' '2013-2014' '2012-2013' '2011-2012' '2010-2011' '2009-2010'\n",
      " '2008-2009' '2007-2008' '2006-2007' '2005-2006' '2004-2005' '2003-2004']\n",
      "['Ajax' 'Atlético Madrid' 'Barcelona' 'Bayern Munich' 'Benfica' 'Celtic'\n",
      " 'Chelsea' 'Club Brugge' 'Dinamo Zagreb' 'Dortmund' 'Eint Frankfurt'\n",
      " 'FC Copenhagen' 'Inter' 'Juventus' 'Leverkusen' 'Liverpool'\n",
      " 'Maccabi Haifa' 'Manchester City' 'Marseille' 'Milan' 'Napoli'\n",
      " 'Paris S-G' 'Porto' 'Rangers' 'RB Leipzig' 'RB Salzburg' 'Real Madrid'\n",
      " 'Sevilla' 'Shakhtar' 'Sporting CP' 'Tottenham' 'Viktoria Plzeň'\n",
      " 'Atalanta' 'Beşiktaş' 'Dynamo Kyiv' 'Lille' 'Malmö' 'Manchester Utd'\n",
      " 'Sheriff Tiraspol' 'Villarreal' 'Wolfsburg' 'Young Boys' 'ruZen'\n",
      " 'Başakşehir' 'Ferencváros' 'Krasnodar' 'Lazio' 'Loko Moscow' \"M'Gladbach\"\n",
      " 'Midtjylland' 'Olympiacos' 'frRenn' 'Galatasaray' 'Genk' 'Lyon'\n",
      " 'Red Star' 'Slavia Prague' 'Valencia' 'AEK Athens' 'CSKA Moscow'\n",
      " 'Hoffenheim' 'Monaco' 'PSV Eindhoven' 'Roma' 'Schalke 04' 'Arsenal'\n",
      " 'Basel' 'Legia Warsaw' 'Leicester City' 'Ludogorets' 'Rostov'\n",
      " 'Anderlecht' 'APOEL FC' 'Athletic Club' 'BATE Borisov' 'NK Maribor'\n",
      " 'Austria Wien' 'Real Sociedad' 'Steaua' 'Braga' 'CFR Cluj' 'Málaga'\n",
      " 'Montpellier' 'Nordsjælland' 'Spartak Moscow' 'Oțelul Galați'\n",
      " 'Trabzonspor' 'Auxerre' 'Bursaspor' 'Hapoel Tel Aviv' 'MŠK Žilina'\n",
      " 'Panathinaikos' 'Partizan' 'Rubin Kazan' 'Twente' 'Werr Bremen'\n",
      " 'AZ Alkmaar' 'Bordeaux' 'Debrecen' 'Fiorentina' 'Standard Liège'\n",
      " 'Stuttgart' 'Unirea Urziceni' 'Züri' 'Aalborg' 'Anorthosis' 'Fenerbahçe'\n",
      " 'Rosenborg' 'Hamburger SV' 'Levski Sofia' 'Artmedia' 'Betis' 'Rapid Wien'\n",
      " 'Sparta Prague' 'Thun' 'Udinese' 'La Coruña' 'Maccabi Tel Aviv'\n",
      " 'Celta Vigo']\n",
      "['Países bajos' 'España' 'Alemania' 'Portugal' 'Escocia' 'Inglaterra'\n",
      " 'Bélgica' 'Croacia' 'Dinamarca' 'Italia' 'Israel' 'Francia' 'Austria'\n",
      " 'Ucrania' 'República checa' 'Turquía' 'Suecia' 'Moldavia' 'Suiza'\n",
      " 'Hungría' 'Rusia' 'Grecia' 'Serbia' 'Polonia' 'Bulgaria' 'Chipre'\n",
      " 'Bielorrusia' 'Eslovenia' 'Rumanía' 'Eslovaquia' 'Noruega']\n"
     ]
    }
   ],
   "source": [
    "print(datos['Season'].unique())\n",
    "print(datos['Squad'].unique())\n",
    "print(datos['Country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay muchos equipos diferentes, así que no vale la pena convertir esta columna a numérica. Sin embargo, el resto de columas sí que vale la pena convertirlas a numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2003-2004': 0, '2004-2005': 1, '2005-2006': 2, '2006-2007': 3, '2007-2008': 4, '2008-2009': 5, '2009-2010': 6, '2010-2011': 7, '2011-2012': 8, '2012-2013': 9, '2013-2014': 10, '2014-2015': 11, '2016-2017': 12, '2018-2019': 13, '2019-2020': 14, '2020-2021': 15, '2021-2022': 16, '2022-2023': 17}\n"
     ]
    }
   ],
   "source": [
    "# Columna 'Season'\n",
    "le = LabelEncoder().fit(datos['Season'])\n",
    "datos['Season'] = le.transform(datos['Season'])\n",
    "\n",
    "# Obtenemos los valores únicos originales\n",
    "valores_originales = le.classes_\n",
    "# Creamos un diccionario de mapeo para ver a qué valor numérico corresponde cada valor original\n",
    "temporada = dict(zip(valores_originales, le.transform(valores_originales)))\n",
    "\n",
    "print(temporada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alemania': 0, 'Austria': 1, 'Bielorrusia': 2, 'Bulgaria': 3, 'Bélgica': 4, 'Chipre': 5, 'Croacia': 6, 'Dinamarca': 7, 'Escocia': 8, 'Eslovaquia': 9, 'Eslovenia': 10, 'España': 11, 'Francia': 12, 'Grecia': 13, 'Hungría': 14, 'Inglaterra': 15, 'Israel': 16, 'Italia': 17, 'Moldavia': 18, 'Noruega': 19, 'Países bajos': 20, 'Polonia': 21, 'Portugal': 22, 'República checa': 23, 'Rumanía': 24, 'Rusia': 25, 'Serbia': 26, 'Suecia': 27, 'Suiza': 28, 'Turquía': 29, 'Ucrania': 30}\n"
     ]
    }
   ],
   "source": [
    "# Columna 'Country'\n",
    "le = LabelEncoder().fit(datos['Country'])\n",
    "datos['Country'] = le.transform(datos['Country'])\n",
    "\n",
    "# Obtenemos los valores únicos originales\n",
    "valores_originales = le.classes_\n",
    "# Creamos un diccionario de mapeo para ver a qué valor numérico corresponde cada valor original\n",
    "paises = dict(zip(valores_originales, le.transform(valores_originales)))\n",
    "\n",
    "print(paises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Último paso de la ingeniería de variables, eliminamos variables categóricas y realizamos un escalado de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la única columna no numérica que queda\n",
    "datos = datos.drop(columns=['Squad'])\n",
    "\n",
    "# Escalamos los datos para mejorar la efectividad de los algoritmos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos los algoritmos de clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    \"KMeans\": KMeans(n_clusters=3),\n",
    "    \"MeanShift\": MeanShift(),\n",
    "    \"DBSCAN\": DBSCAN(eps=0.5, min_samples=5),\n",
    "    \"OPTICS\": OPTICS(),\n",
    "    \"GMM\": GaussianMixture(n_components=3),\n",
    "    \"AgglomerativeClustering\": AgglomerativeClustering(n_clusters=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteramos sobre varios algoritmos de clustering, aplicamos cada algoritmo al conjunto de datos, contamos el número de clusters encontrados por cada algoritmo y luego imprimimos esta información para cada algoritmo. Esto permite comparar cómo cada algoritmo agrupa los datos y cuántos clusters encuentra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans: 3 clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanShift: 1 clusters\n",
      "DBSCAN: 0 clusters\n",
      "OPTICS: 4 clusters\n",
      "GMM: 3 clusters\n",
      "AgglomerativeClustering: 3 clusters\n"
     ]
    }
   ],
   "source": [
    "for name, algorithm in algorithms.items():\n",
    "    cluster_labels = algorithm.fit_predict(X_scaled)\n",
    "    if cluster_labels is not None:\n",
    "        n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "        print(f\"{name}: {n_clusters} clusters\")\n",
    "    else:\n",
    "        print(f\"Error: {name} algorithm returned None\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

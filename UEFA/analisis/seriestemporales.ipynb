{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Series Temporales**\n",
    "\n",
    "En este archivo desarrollaremos las siguientes series temporales:\n",
    "- Time Series Forecasting en Python.\n",
    "- Modelos estadísticos (AR, ARIMA, SARIMA, Exponential Smoothing).\n",
    "- Recursive Forecasting (Random Forest, Gradient Boosting Regression).\n",
    "- Multivariate Forecasting, Ensemble modeling.\n",
    "\n",
    "Primero importamos todas las librerías que usaremos y las instalamos en caso de ser necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\laura rodríguez\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# Instalamos las librerías necesarias\n",
    "%pip install pandas\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El próximo paso es cargar los datos limpios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Country</th>\n",
       "      <th># Pl</th>\n",
       "      <th>Age</th>\n",
       "      <th>MP</th>\n",
       "      <th>Starts</th>\n",
       "      <th>Gls</th>\n",
       "      <th>Ast</th>\n",
       "      <th>G+A</th>\n",
       "      <th>G-PK</th>\n",
       "      <th>PK</th>\n",
       "      <th>PKatt</th>\n",
       "      <th>CrdY</th>\n",
       "      <th>CrdR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Países bajos</td>\n",
       "      <td>19</td>\n",
       "      <td>26.4</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Atlético Madrid</td>\n",
       "      <td>España</td>\n",
       "      <td>22</td>\n",
       "      <td>28.6</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>España</td>\n",
       "      <td>26</td>\n",
       "      <td>26.4</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>Alemania</td>\n",
       "      <td>24</td>\n",
       "      <td>26.6</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>Benfica</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>24</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season            Squad       Country  # Pl   Age  MP  Starts  Gls  Ast  \\\n",
       "0  2022-2023             Ajax  Países bajos    19  26.4   6      66   11    9   \n",
       "1  2022-2023  Atlético Madrid        España    22  28.6   6      66    4    3   \n",
       "2  2022-2023        Barcelona        España    26  26.4   6      66   12   10   \n",
       "3  2022-2023    Bayern Munich      Alemania    24  26.6  10     110   21   19   \n",
       "4  2022-2023          Benfica      Portugal    24  26.0  10     110   25   16   \n",
       "\n",
       "   G+A  G-PK  PK  PKatt  CrdY  CrdR  \n",
       "0   20    10   1      1  15.0   1.0  \n",
       "1    7     4   0      2  11.0   0.0  \n",
       "2   22    12   0      0   9.0   0.0  \n",
       "3   40    20   1      1  20.0   1.0  \n",
       "4   41    20   5      5  19.0   0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv('../data/equipos_limpio.csv')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la información general de nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 640 entries, 0 to 639\n",
      "Data columns (total 15 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Season   640 non-null    object \n",
      " 1   Squad    640 non-null    object \n",
      " 2   Country  640 non-null    object \n",
      " 3   # Pl     640 non-null    int64  \n",
      " 4   Age      640 non-null    float64\n",
      " 5   MP       640 non-null    int64  \n",
      " 6   Starts   640 non-null    int64  \n",
      " 7   Gls      640 non-null    int64  \n",
      " 8   Ast      640 non-null    int64  \n",
      " 9   G+A      640 non-null    int64  \n",
      " 10  G-PK     640 non-null    int64  \n",
      " 11  PK       640 non-null    int64  \n",
      " 12  PKatt    640 non-null    int64  \n",
      " 13  CrdY     576 non-null    float64\n",
      " 14  CrdR     576 non-null    float64\n",
      "dtypes: float64(3), int64(9), object(3)\n",
      "memory usage: 75.1+ KB\n"
     ]
    }
   ],
   "source": [
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que todavía tenemos algunas filas nulas. Al limpiar los datos no nos importaba tener algunas filas nulas, pero para hacer la clasterización es muy importante no contar con ningún dato de este tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 576 entries, 0 to 639\n",
      "Data columns (total 15 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Season   576 non-null    object \n",
      " 1   Squad    576 non-null    object \n",
      " 2   Country  576 non-null    object \n",
      " 3   # Pl     576 non-null    int64  \n",
      " 4   Age      576 non-null    float64\n",
      " 5   MP       576 non-null    int64  \n",
      " 6   Starts   576 non-null    int64  \n",
      " 7   Gls      576 non-null    int64  \n",
      " 8   Ast      576 non-null    int64  \n",
      " 9   G+A      576 non-null    int64  \n",
      " 10  G-PK     576 non-null    int64  \n",
      " 11  PK       576 non-null    int64  \n",
      " 12  PKatt    576 non-null    int64  \n",
      " 13  CrdY     576 non-null    float64\n",
      " 14  CrdR     576 non-null    float64\n",
      "dtypes: float64(3), int64(9), object(3)\n",
      "memory usage: 72.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos las filas que contienen valores nulos\n",
    "datos = datos.dropna()\n",
    "\n",
    "# Vemos que se ha hecho el cambio correctamente\n",
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que hay algunas variables categóricas que podríamos pasar a numéricas, pues nos podrían ayudar en nuestra predicción posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-2023' '2021-2022' '2020-2021' '2019-2020' '2018-2019' '2016-2017'\n",
      " '2014-2015' '2013-2014' '2012-2013' '2011-2012' '2010-2011' '2009-2010'\n",
      " '2008-2009' '2007-2008' '2006-2007' '2005-2006' '2004-2005' '2003-2004']\n",
      "['Ajax' 'Atlético Madrid' 'Barcelona' 'Bayern Munich' 'Benfica' 'Celtic'\n",
      " 'Chelsea' 'Club Brugge' 'Dinamo Zagreb' 'Dortmund' 'Eint Frankfurt'\n",
      " 'FC Copenhagen' 'Inter' 'Juventus' 'Leverkusen' 'Liverpool'\n",
      " 'Maccabi Haifa' 'Manchester City' 'Marseille' 'Milan' 'Napoli'\n",
      " 'Paris S-G' 'Porto' 'Rangers' 'RB Leipzig' 'RB Salzburg' 'Real Madrid'\n",
      " 'Sevilla' 'Shakhtar' 'Sporting CP' 'Tottenham' 'Viktoria Plzeň'\n",
      " 'Atalanta' 'Beşiktaş' 'Dynamo Kyiv' 'Lille' 'Malmö' 'Manchester Utd'\n",
      " 'Sheriff Tiraspol' 'Villarreal' 'Wolfsburg' 'Young Boys' 'ruZen'\n",
      " 'Başakşehir' 'Ferencváros' 'Krasnodar' 'Lazio' 'Loko Moscow' \"M'Gladbach\"\n",
      " 'Midtjylland' 'Olympiacos' 'frRenn' 'Galatasaray' 'Genk' 'Lyon'\n",
      " 'Red Star' 'Slavia Prague' 'Valencia' 'AEK Athens' 'CSKA Moscow'\n",
      " 'Hoffenheim' 'Monaco' 'PSV Eindhoven' 'Roma' 'Schalke 04' 'Arsenal'\n",
      " 'Basel' 'Legia Warsaw' 'Leicester City' 'Ludogorets' 'Rostov'\n",
      " 'Anderlecht' 'APOEL FC' 'Athletic Club' 'BATE Borisov' 'NK Maribor'\n",
      " 'Austria Wien' 'Real Sociedad' 'Steaua' 'Braga' 'CFR Cluj' 'Málaga'\n",
      " 'Montpellier' 'Nordsjælland' 'Spartak Moscow' 'Oțelul Galați'\n",
      " 'Trabzonspor' 'Auxerre' 'Bursaspor' 'Hapoel Tel Aviv' 'MŠK Žilina'\n",
      " 'Panathinaikos' 'Partizan' 'Rubin Kazan' 'Twente' 'Werr Bremen'\n",
      " 'AZ Alkmaar' 'Bordeaux' 'Debrecen' 'Fiorentina' 'Standard Liège'\n",
      " 'Stuttgart' 'Unirea Urziceni' 'Züri' 'Aalborg' 'Anorthosis' 'Fenerbahçe'\n",
      " 'Rosenborg' 'Hamburger SV' 'Levski Sofia' 'Artmedia' 'Betis' 'Rapid Wien'\n",
      " 'Sparta Prague' 'Thun' 'Udinese' 'La Coruña' 'Maccabi Tel Aviv'\n",
      " 'Celta Vigo']\n",
      "['Países bajos' 'España' 'Alemania' 'Portugal' 'Escocia' 'Inglaterra'\n",
      " 'Bélgica' 'Croacia' 'Dinamarca' 'Italia' 'Israel' 'Francia' 'Austria'\n",
      " 'Ucrania' 'República checa' 'Turquía' 'Suecia' 'Moldavia' 'Suiza'\n",
      " 'Hungría' 'Rusia' 'Grecia' 'Serbia' 'Polonia' 'Bulgaria' 'Chipre'\n",
      " 'Bielorrusia' 'Eslovenia' 'Rumanía' 'Eslovaquia' 'Noruega']\n"
     ]
    }
   ],
   "source": [
    "print(datos['Season'].unique())\n",
    "print(datos['Squad'].unique())\n",
    "print(datos['Country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay muchos equipos diferentes, así que no vale la pena convertir esta columna a numérica. Sin embargo, el resto de columas sí que vale la pena convertirlas a numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2003-2004': 0, '2004-2005': 1, '2005-2006': 2, '2006-2007': 3, '2007-2008': 4, '2008-2009': 5, '2009-2010': 6, '2010-2011': 7, '2011-2012': 8, '2012-2013': 9, '2013-2014': 10, '2014-2015': 11, '2016-2017': 12, '2018-2019': 13, '2019-2020': 14, '2020-2021': 15, '2021-2022': 16, '2022-2023': 17}\n"
     ]
    }
   ],
   "source": [
    "# Columna 'Season'\n",
    "le = LabelEncoder().fit(datos['Season'])\n",
    "datos['Season'] = le.transform(datos['Season'])\n",
    "\n",
    "# Obtenemos los valores únicos originales\n",
    "valores_originales = le.classes_\n",
    "# Creamos un diccionario de mapeo para ver a qué valor numérico corresponde cada valor original\n",
    "temporada = dict(zip(valores_originales, le.transform(valores_originales)))\n",
    "\n",
    "print(temporada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alemania': 0, 'Austria': 1, 'Bielorrusia': 2, 'Bulgaria': 3, 'Bélgica': 4, 'Chipre': 5, 'Croacia': 6, 'Dinamarca': 7, 'Escocia': 8, 'Eslovaquia': 9, 'Eslovenia': 10, 'España': 11, 'Francia': 12, 'Grecia': 13, 'Hungría': 14, 'Inglaterra': 15, 'Israel': 16, 'Italia': 17, 'Moldavia': 18, 'Noruega': 19, 'Países bajos': 20, 'Polonia': 21, 'Portugal': 22, 'República checa': 23, 'Rumanía': 24, 'Rusia': 25, 'Serbia': 26, 'Suecia': 27, 'Suiza': 28, 'Turquía': 29, 'Ucrania': 30}\n"
     ]
    }
   ],
   "source": [
    "# Columna 'Country'\n",
    "le = LabelEncoder().fit(datos['Country'])\n",
    "datos['Country'] = le.transform(datos['Country'])\n",
    "\n",
    "# Obtenemos los valores únicos originales\n",
    "valores_originales = le.classes_\n",
    "# Creamos un diccionario de mapeo para ver a qué valor numérico corresponde cada valor original\n",
    "paises = dict(zip(valores_originales, le.transform(valores_originales)))\n",
    "\n",
    "print(paises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras haber cambiado algunas columnas de categóricas a numéricas, eliminamos aquellas columnas que todavía son categóricas. En nuestro caso es sólo la columna 'Squad'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la única columna no numérica que queda\n",
    "datos = datos.drop(columns=['Squad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos las Series Temporales separando los datos en entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos nuestras variables x e y\n",
    "x = datos.drop('Gls',axis=1)\n",
    "y = datos['Gls']\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos los modelos estadísticos de series temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\deterministic.py:302: UserWarning: Only PeriodIndexes, DatetimeIndexes with a frequency set, RangesIndexes, and Index with a unit increment support extending. The index is set will contain the position relative to the data length.\n",
      "  fcast_index = self._extend_index(index, steps, forecast_index)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:834: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "# AR\n",
    "model_ar = AutoReg(y_train, lags=5)\n",
    "fit_ar = model_ar.fit()\n",
    "predictions_ar = fit_ar.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1)\n",
    "\n",
    "# ARIMA\n",
    "model_arima = ARIMA(y_train, order=(5,1,0))\n",
    "fit_arima = model_arima.fit()\n",
    "predictions_arima = fit_arima.forecast(steps=len(y_test))\n",
    "\n",
    "# SARIMA\n",
    "model_sarima = SARIMAX(y_train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "fit_sarima = model_sarima.fit()\n",
    "predictions_sarima = fit_sarima.forecast(steps=len(y_test))\n",
    "\n",
    "# Exponential Smoothing\n",
    "model_exp = ExponentialSmoothing(y_train, seasonal='add', seasonal_periods=12)\n",
    "fit_exp = model_exp.fit()\n",
    "predictions_exp = fit_exp.forecast(steps=len(y_test))\n",
    "\n",
    "# Modelos de aprendizaje automático\n",
    "# Random Forest\n",
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(x_train, y_train)\n",
    "predictions_rf = model_rf.predict(x_test)\n",
    "\n",
    "# Gradient Boosting Regression\n",
    "model_gb = GradientBoostingRegressor()\n",
    "model_gb.fit(x_train, y_train)\n",
    "predictions_gb = model_gb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos su error cuadrático medio para evaluar el rendimiento de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadrático Medio (AR): 47.35889765240159\n",
      "Error Cuadrático Medio (ARIMA): 48.55417076659892\n",
      "Error Cuadrático Medio (SARIMA): 49.96725909470113\n",
      "Error Cuadrático Medio (Exponential Smoothing): 49.722837386139716\n",
      "Error Cuadrático Medio (Random Forest): 0.581993063583815\n",
      "Error Cuadrático Medio (Gradient Boosting): 0.2995891050540855\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del rendimiento\n",
    "mse_ar = mean_squared_error(y_test, predictions_ar)\n",
    "mse_arima = mean_squared_error(y_test, predictions_arima)\n",
    "mse_sarima = mean_squared_error(y_test, predictions_sarima)\n",
    "mse_exp = mean_squared_error(y_test, predictions_exp)\n",
    "mse_rf = mean_squared_error(y_test, predictions_rf)\n",
    "mse_gb = mean_squared_error(y_test, predictions_gb)\n",
    "\n",
    "print(\"Error Cuadrático Medio (AR):\", mse_ar)\n",
    "print(\"Error Cuadrático Medio (ARIMA):\", mse_arima)\n",
    "print(\"Error Cuadrático Medio (SARIMA):\", mse_sarima)\n",
    "print(\"Error Cuadrático Medio (Exponential Smoothing):\", mse_exp)\n",
    "print(\"Error Cuadrático Medio (Random Forest):\", mse_rf)\n",
    "print(\"Error Cuadrático Medio (Gradient Boosting):\", mse_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Error Cuadrático Medio (ECM) cuantifica el promedio de los errores cuadráticos entre las predicciones del modelo y los valores reales. Un ECM más bajo indica que el modelo tiene una mejor capacidad para predecir los valores reales, mientras que un ECM más alto indica que el modelo tiene una peor capacidad predictiva.\n",
    "\n",
    "Por lo tanto, comparando los valores de los ECMs para cada modelo, podemos concluir que los mejores modelos (es decir, aquellos que predicen mejor) es el Random Forest y el Gradient Boosting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
